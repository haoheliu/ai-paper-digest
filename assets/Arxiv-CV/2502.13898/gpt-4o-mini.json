{
    "title": "GroundCap: A Visually Grounded Image Captioning Dataset",
    "author": "Daniel A. P. Oliveira (INESC-ID Lisboa, Instituto Superior T\u00e9cnico), Louren\u00e7o Teodoro (INESC-ID Lisboa), David Martins de Matos (INESC-ID Lisboa, Instituto Superior T\u00e9cnico), ...",
    "quality": 6,
    "relevance": 5,
    "relevance_why": "",
    "field": "Applications-Vision",
    "background": "Visually grounded image captioning involves generating descriptive text for images by linking specific textual elements to identifiable visual components.",
    "contribution": "GroundCap introduces a dataset of 52,016 images with grounded captions to enhance visual grounding in image captioning, improving the reliability of generated textual descriptions.",
    "technical_comparison": {
        "prior_work": "Existing image captioning models often lack the ability to consistently reference specific objects or actions across descriptions.",
        "novelty": "This dataset and its associated grounding framework facilitate the tracking of object identities and the simultaneous grounding of actions, addressing limitations in prior approaches."
    },
    "key_innovation": "Implements a unique tagging system that connects actions and objects while maintaining distinct identifying tags for each object across multiple references.",
    "real_world_impact": "Enhances the accuracy and reliability of image captioning systems, which can benefit applications in accessibility technologies, content generation, and robotics vision.",
    "limitations": "No",
    "new_terms": {
        "grounding": "**Grounding** in this context refers to the process of linking specific language elements to their corresponding visual representations in an image.",
        "gMETEOR": "**gMETEOR** is a proposed metric that assesses both the quality of generated captions and the accuracy of the grounding process."
    },
    "open_sourcing": "The dataset and fine-tuned model are publicly available on Hugging Face."
}