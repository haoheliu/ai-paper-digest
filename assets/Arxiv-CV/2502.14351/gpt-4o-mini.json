{
    "title": "SegAnyPET: Universal Promptable Segmentation from Positron Emission Tomography Images",
    "author": "Yichi Zhang (Fudan University), Le Xue (Fudan University), Wenbo Zhang (Fudan University), Lanlan Li (Fudan University), Yuchen Liu (Fudan University), Chen Jiang (Shanghai Academy of Artificial Intelligence for Science), Yuan Cheng (Fudan University), Yuan Qi (Fudan University)",
    "quality": 8,
    "relevance": 5,
    "relevance_why": "",
    "field": "Applications-Vision",
    "background": "Universal promptable segmentation of three-dimensional Positron Emission Tomography images that helps in identifying organs and lesions in medical imaging.",
    "contribution": "SegAnyPET introduces a 3D foundation model for promptable segmentation to solve challenges associated with low-quality PET image segmentation, achieving superior accuracy over existing models.",
    "technical_comparison": {
        "prior_work": "Traditional segmentation methods struggle with low contrast and varied quality in medical images, often requiring large amounts of expert-annotated data.",
        "novelty": "This work improves by introducing a cross prompting confident learning strategy, allowing it to leverage both high-quality and noisy annotations efficiently."
    },
    "key_innovation": "Develops the largest PET segmentation dataset and a specialized 3D model that can generalize from minimal prompts to effectively segment unseen targets.",
    "real_world_impact": "Potentially transforms medical imaging processes in oncology by enhancing the accuracy of tumor and organ segmentation, thus aiding in diagnosis and treatment monitoring.",
    "limitations": "The manual prompting requirement may limit the model's applicability in fully automated settings.",
    "new_terms": {
        "cross prompting confident learning": "**Cross prompting confident learning** is a strategy that allows a model to adaptively use both high-quality and low-quality annotations during training to improve segmentation outcomes."
    },
    "open_sourcing": "The model and code will be publicly available at https://github.com/YichiZhang98/SegAnyPET"
}