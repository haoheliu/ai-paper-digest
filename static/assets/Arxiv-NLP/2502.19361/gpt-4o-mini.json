{
    "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?",
    "author": "Yancheng He (Alibaba Group), Shilong Li (Alibaba Group), Jiaheng Liu (Alibaba Group), Weixun Wang (Alibaba Group), Xingyuan Bu (Alibaba Group), Ge Zhang (M-A-P), Zhongyuan Peng (Alibaba Group), Zhaoxiang Zhang (CASIA), Wenbo Su (Alibaba Group), Bo Zheng (Alibaba Group)",
    "quality": 7,
    "relevance": 8,
    "relevance_why": "The paper explores error detection in reasoning processes generated by large language models, relevant for improving models in speech and audio applications, where reasoning and critique of generated outputs could enhance performance.",
    "field": "Deep Learning-Large Language Models (LLMs)",
    "background": "The task investigates the ability of various Large Language Models (LLMs) to identify and correct errors in their reasoning processes as demonstrated by Chain-of-Thought (CoT) outputs.",
    "contribution": "This paper introduces DeltaBench, a dataset that benchmarks the effectiveness of LLMs in detecting errors within Chain-of-Thought reasoning tasks, aiming to enhance model critique capabilities.",
    "technical_comparison": {
        "prior_work": "Previous evaluations mainly focused on individual reasoning steps or overall correctness.",
        "novelty": "This work analyzes error detection at a section level, enabling a finer-grained assessment of reasoning quality across multiple tasks."
    },
    "key_innovation": "DeltaBench allows for a more detailed analysis of long CoT outputs and the errors within those outputs, significantly improving the evaluation of model critique abilities.",
    "real_world_impact": "The findings can inform better model designs and training strategies, ultimately leading to more reliable AI systems in various application domains, including education and automated reasoning.",
    "limitations": "The critique abilities of existing models remain limited, achieving only moderate performance in detecting errors.",
    "new_terms": {
        "Long Chain-of-Thought (CoT)": "**Long Chain-of-Thought (CoT)** reasoning refers to a method where models generate a sequence of reasoning steps to arrive at conclusions, which is essential for complex problem-solving tasks.",
        "Process Reward Models (PRMs)": "**Process Reward Models (PRMs)** are models specifically designed to evaluate and provide feedback on the reasoning processes produced by other models."
    },
    "open_sourcing": "The dataset DeltaBench is available at https://github.com/OpenStellarTeam/DeltaBench"
}