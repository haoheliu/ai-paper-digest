{
    "title": "An Analyst-Inspector Framework for Evaluating Reproducibility of LLMs in Data Science",
    "author": "Qiuhai Zeng (Pennsylvania State University), Claire Jin (Carnegie Mellon University), Xinyue Wang (Pennsylvania State University), Yuhan Zheng (International Monetary Fund), Qunhua Li (Pennsylvania State University)",
    "quality": 8,
    "relevance": 7,
    "relevance_why": "The proposed framework for assessing reproducibility directly addresses issues in LLM outputs, which can enhance reproducibility in audio generation tasks that rely on language models.",
    "field": "Evaluation-Replicability and Validity",
    "background": "This paper presents a method to automatically verify the reproducibility of data science workflows generated by large language models (LLMs), ensuring consistent analysis results through an independent evaluation system.",
    "contribution": "The framework introduces an Analyst-Inspector system that evaluates and enforces reproducibility of LLM-generated data analysis, achieving enhanced accuracy and transparency.",
    "technical_comparison": {
        "prior_work": "Existing methods for ensuring reproducibility focus mainly on manual code reviews and lack systematic approaches.",
        "novelty": "This work introduces an independent inspection step that assesses the reproducibility of workflows and outputs generated by LLMs, reducing reliance on subjective human analysis."
    },
    "key_innovation": "Implementing a two-agent system (analyst and inspector) to autonomously evaluate and validate workflows generated by language models.",
    "real_world_impact": "This framework has significant implications for improving the trustworthiness of AI-driven data analysis, which is critical for research and data-driven decision-making in various fields.",
    "limitations": "No",
    "new_terms": {
        "Analyst-Inspector framework": "**Analyst-Inspector framework** refers to a dual-agent approach where one agent generates analytical workflows while an independent agent evaluates their reproducibility, ensuring high standards for automated data analysis."
    },
    "open_sourcing": "https://github.com/qunhualilab/LLM-DS-Reproducibility"
}