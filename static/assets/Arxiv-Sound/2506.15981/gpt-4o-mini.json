{
    "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion",
    "author": "Markus Frohmann (Deezer Research, Paris, France), Gabriel Meseguer Brocal (Deezer Research, Paris, France), Markus Schedl (Johannes Kepler University Linz, Austria), Elena V. Epure (Deezer Research, Paris, France), Johannes Kepler University Linz, Austria, Linz Institute of Technology, AI Lab, Austria, ..., Gabriel Meseguer Brocal (Deezer Research, Paris, France)",
    "quality": 7,
    "relevance": 8,
    "relevance_why": "This work focuses on detecting AI-generated lyrics through a robust multimodal approach, which could be relevant for Haohe Liu's research in audio and music processing, particularly in the context of generative models and audio analysis.",
    "field": "Applications-Speech and Audio",
    "background": "The task is to detect whether a piece of music has lyrics generated by an artificial intelligence model, using audio input alone without relying on accurate lyric transcriptions.",
    "contribution": "This paper introduces a multimodal late-fusion pipeline combining transcribed lyrics and speech features to robustly detect AI-generated music lyrics, achieving improved detection rates even with audio perturbations.",
    "technical_comparison": "Previous methods relied heavily on cleanly formatted lyrics or were sensitive to audio perturbations, leading to generalization issues. This work addresses these limitations by utilizing both audio-derived transcripts and speech embeddings, enhancing robustness and detection performance.",
    "key_innovation": "It uniquely integrates audio features with automatic lyric transcription, allowing for a more resilient detection strategy that does not depend on perfect lyric formatting.",
    "real_world_impact": "This method can significantly improve copyright protection and transparency in music streaming, addressing real concerns about the rise of AI-generated content in the music industry.",
    "limitations": "While it shows promise, the evaluation is heavily based on a single generator and may not generalize across all types of AI-generated music.",
    "new_terms": {
        "multimodal late-fusion": "**Multimodal late-fusion** refers to a technique that combines multiple sources of information (e.g., text and audio) to improve the performance of a model by leveraging diverse features.",
        "speech embeddings": "**Speech embeddings** are representations derived from audio signals that capture meaningful information about the acoustic properties and characteristics of speech, which can aid in tasks like detection and classification."
    },
    "open_sourcing": "The code is available at [https://github.com/deezer/robust-AI-lyrics-detection](https://github.com/deezer/robust-AI-lyrics-detection)"
}