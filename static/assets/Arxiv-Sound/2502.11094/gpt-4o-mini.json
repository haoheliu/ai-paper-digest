{
    "title": "SyncSpeech: Low-Latency and Efficient Dual-Stream Text-to-Speech based on Temporal Masked Transformer",
    "author": "Zhengyan Sheng (University of Science and Technology of China), Zhihao Du (Speech Lab, Alibaba Group), Shiliang Zhang (Speech Lab, Alibaba Group), Zhijie Yan (Speech Lab, Alibaba Group), Yexin Yang (Speech Lab, Alibaba Group), Zhenhua Ling (University of Science and Technology of China)",
    "quality": 8,
    "relevance": 7,
    "relevance_why": "This paper presents a novel approach to low-latency text-to-speech systems, which can be useful for improving real-time audio generation tasks in Haohe Liu's research, particularly in audio quality enhancement and restoration systems that require efficient text-to-speech integration.",
    "field": "Applications-Speech and Audio",
    "background": "This research focuses on improving text-to-speech systems that can generate speech in real-time while processing streaming text inputs.",
    "contribution": "SyncSpeech introduces a dual-stream text-to-speech architecture to solve low-latency issues in real-time speech generation, achieving significantly improved generation speeds compared to traditional models.",
    "technical_comparison": {
        "prior_work": "Previous text-to-speech models often require complete text input before generation, leading to higher latency and less efficiency.",
        "novelty": "SyncSpeech reduces latency by starting speech generation as soon as the second text token is received, and only requires one decoding step for multiple corresponding speech tokens."
    },
    "key_innovation": "The model utilizes a Temporally Masked Transformer that combines duration and speech token predictions in a unified framework, enhancing the efficiency of streaming text-to-speech.",
    "real_world_impact": "The approach could significantly enhance applications like virtual assistants and real-time translation systems, making them more responsive and efficient for users.",
    "limitations": "The requirement for token-level alignment data complicates preprocessing, especially for mixed language inputs.",
    "new_terms": {
        "Temporal Masked Transformer": "**Temporal Masked Transformer** refers to a specialized transformer model designed to handle temporally-ordered tasks in audio synthesis, allowing for efficient real-time performance."
    },
    "open_sourcing": "Speech samples are available at https://SyncSpeech.github.io/"
}